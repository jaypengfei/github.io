---
layout: post
title:  EM算法
date:   2017-08-1 21:37:00 +0800
categories: 机器学习
tag: 机器学习
---

* content
{:toc}


&emsp;&emsp;最近在看到机器学习中关于贝叶斯分类器的相关内容，其中介绍了EM算法，但是并没有很好的理解其中的原理。正好手头有一本《统计学习方法》，里面有完整的一章介绍了EM算法，讲解较为细致。所以我就把相关的内容整理 了一下，写到这里。
<hr>
&emsp;&emsp;以下内容参考《李航：统计学习方法》
<hr>
&emsp;&emsp;概率模型有时既含有观测变量，又含有隐变量。如果概率模型的变量都是观测变量，那么给定数据。可以直接使用极大似然估计法，或贝叶斯估计法估计模型参数。但是当含有隐变量时，就不能简单地使用这些估计方法。EM算法就是含有隐变量的概率模型参数的极大似然估计法，或极大后验概率估计法。<br>

一个例子
====================================

![em]({{ '/styles/images/em/em1.png' | prepend: site.baseurl }})
![em]({{ '/styles/images/em/em2.png' | prepend: site.baseurl }})
![em]({{ '/styles/images/em/em3.png' | prepend: site.baseurl }})

<hr>
​最后的最后，老婆我爱你。








